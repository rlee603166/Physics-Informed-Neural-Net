{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance PINN Training - Two-Stage with GPU Optimization\n",
    "\n",
    "**BEFORE RUNNING: Upload these files to Colab:**\n",
    "1. `processed_data/` folder (containing batch_0.h5, batch_1.h5)\n",
    "2. `user_ages.csv`\n",
    "3. `improved_models.py`\n",
    "4. `enhanced_datasets.py`\n",
    "5. `training_utils.py`\n",
    "6. `config.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install matplotlib seaborn pyyaml h5py pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Validation and Performance Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"=== GPU VALIDATION ===\")\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name}\")\n",
    "        print(f\"  Memory: {props.total_memory / 1024**3:.1f}GB\")\n",
    "        print(f\"  Compute Capability: {props.major}.{props.minor}\")\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(0)\n",
    "    \n",
    "    # GPU memory test\n",
    "    print(\"\\n=== GPU MEMORY TEST ===\")\n",
    "    test_tensor = torch.randn(10000, 10000, device=device)\n",
    "    memory_allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    memory_reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "    print(f\"Test allocation: {memory_allocated:.2f}GB allocated, {memory_reserved:.2f}GB reserved\")\n",
    "    del test_tensor\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # GPU compute test\n",
    "    print(\"\\n=== GPU COMPUTE TEST ===\")\n",
    "    start_time = time.time()\n",
    "    a = torch.randn(5000, 5000, device=device)\n",
    "    b = torch.randn(5000, 5000, device=device)\n",
    "    c = torch.matmul(a, b)\n",
    "    torch.cuda.synchronize()  # Wait for GPU to finish\n",
    "    compute_time = time.time() - start_time\n",
    "    print(f\"Matrix multiplication (5000x5000): {compute_time:.3f} seconds\")\n",
    "    \n",
    "    if compute_time < 0.1:\n",
    "        print(\"✅ GPU is working correctly and fast!\")\n",
    "    else:\n",
    "        print(\"⚠️ GPU compute seems slow - check GPU utilization\")\n",
    "    \n",
    "    del a, b, c\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "else:\n",
    "    print(\"❌ CUDA not available - using CPU (will be very slow!)\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uploaded files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== FILE VERIFICATION ===\")\n",
    "required_files = [\n",
    "    'improved_models.py',\n",
    "    'enhanced_datasets.py',\n",
    "    'training_utils.py', \n",
    "    'config.py',\n",
    "    'user_ages.csv'\n",
    "]\n",
    "\n",
    "missing_files = []\n",
    "for file in required_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"✅ {file}\")\n",
    "    else:\n",
    "        print(f\"❌ {file} - MISSING!\")\n",
    "        missing_files.append(file)\n",
    "\n",
    "if os.path.exists('processed_data'):\n",
    "    batch_files = list(Path('processed_data').glob('batch_*.h5'))\n",
    "    print(f\"✅ processed_data/ - {len(batch_files)} batch files found\")\n",
    "    for batch_file in batch_files:\n",
    "        print(f\"   {batch_file.name}\")\n",
    "else:\n",
    "    print(\"❌ processed_data/ - MISSING!\")\n",
    "    missing_files.append('processed_data/')\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"\\n❌ Please upload missing files: {missing_files}\")\n",
    "    raise SystemExit(\"Missing required files\")\n",
    "else:\n",
    "    print(\"\\n✅ All required files present!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inspection with GPU validation\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "print(\"=== DATA INSPECTION ===\")\n",
    "\n",
    "# Check age data\n",
    "try:\n",
    "    age_df = pd.read_csv('user_ages.csv')\n",
    "    print(f\"Age data: {len(age_df)} subjects\")\n",
    "    print(f\"Age range: {age_df['age'].min():.1f} - {age_df['age'].max():.1f} years\")\n",
    "    print(f\"Age mean ± std: {age_df['age'].mean():.1f} ± {age_df['age'].std():.1f}\")\nexcept Exception as e:\n",
    "    print(f\"Error loading age data: {e}\")\n",
    "\n",
    "# Check batch files\n",
    "try:\n",
    "    total_subjects = set()\n",
    "    total_points = 0\n",
    "    \n",
    "    for batch_file in Path('processed_data').glob('batch_*.h5'):\n",
    "        with h5py.File(batch_file, 'r') as f:\n",
    "            subjects = f['subject_id'][:]\n",
    "            unique_subjects = set(subjects.astype(str))\n",
    "            total_subjects.update(unique_subjects)\n",
    "            points = len(f['t'][:])\n",
    "            total_points += points\n",
    "            print(f\"{batch_file.name}: {len(unique_subjects)} subjects, {points:,} points\")\n",
    "    \n",
    "    print(f\"\\nTotal: {len(total_subjects)} subjects, {total_points:,} data points\")\n",
    "    \n",
    "    # GPU memory estimate\n",
    "    if torch.cuda.is_available():\n",
    "        estimated_memory = (total_points * 4 * 4) / 1024**3  # 4 floats per point, 4 bytes per float\n",
    "        print(f\"Estimated GPU memory needed: {estimated_memory:.1f}GB\")\n",
    "        \n",
    "        available_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        if estimated_memory < available_memory * 0.8:\n",
    "            print(f\"✅ Data will fit in GPU memory ({available_memory:.1f}GB available)\")\n",
    "        else:\n",
    "            print(f\"⚠️ Data might not fit in GPU memory ({available_memory:.1f}GB available)\")\n",
    "            \nexcept Exception as e:\n",
    "    print(f\"Error inspecting batch files: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU-Optimized Configuration for A100\n",
    "print(\"=== PERFORMANCE OPTIMIZATION ===\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory_gb:.1f}GB\")\n",
    "    \n",
    "    # A100 optimized configuration\n",
    "    if 'A100' in gpu_name and gpu_memory_gb > 35:\n",
    "        config = {\n",
    "            # Data loading - optimized for A100\n",
    "            'batch_size': 32768,        # Even larger batches\n",
    "            'num_workers': 8,\n",
    "            'pin_memory': True,\n",
    "            'prefetch_factor': 4,\n",
    "            'persistent_workers': True,\n",
    "            \n",
    "            # Training - A100 optimized\n",
    "            'mixed_precision': True,    # Essential for A100\n",
    "            'compile_model': True,      # PyTorch 2.0 compilation\n",
    "            'gradient_checkpointing': False,  # A100 has enough memory\n",
    "            \n",
    "            # Physics computation - reduced for speed\n",
    "            'use_simplified_physics': True,\n",
    "            'physics_computation_frequency': 8,  # Every 8th batch only\n",
    "            \n",
    "            # Validation - less frequent for speed\n",
    "            'val_frequency': 10,        # Validate every 10 epochs\n",
    "            \n",
    "            # Learning rates - optimized for large batches\n",
    "            'stage1_lr': 3e-3,          # Higher LR for large batches\n",
    "            'stage2_lr': 2e-3,\n",
    "            \n",
    "            # Epochs - reduced with better optimization\n",
    "            'stage1_epochs': 30,        # Should converge faster\n",
    "            'stage2_epochs': 20,\n",
    "            \n",
    "            # Memory management\n",
    "            'empty_cache_frequency': 50,\n",
    "        }\n",
    "        print(\"🚀 A100 ULTRA-FAST CONFIG LOADED\")\n",
    "        print(f\"Expected training time: 30-45 minutes total\")\n",
    "    else:\n",
    "        # Fallback for other GPUs\n",
    "        config = {\n",
    "            'batch_size': 8192,\n",
    "            'num_workers': 4,\n",
    "            'mixed_precision': True,\n",
    "            'physics_computation_frequency': 4,\n",
    "            'stage1_epochs': 50,\n",
    "            'stage2_epochs': 30,\n",
    "            'stage1_lr': 2e-3,\n",
    "            'stage2_lr': 1e-3,\n",
    "        }\n",
    "        print(\"⚡ Standard GPU optimization\")\nelse:\n",
    "    config = {\n",
    "        'batch_size': 2048,\n",
    "        'num_workers': 2,\n",
    "        'mixed_precision': False,\n",
    "        'stage1_epochs': 20,\n",
    "        'stage2_epochs': 15,\n",
    "    }\n",
    "    print(\"⚠️ CPU fallback - will be slow\")\n",
    "\n",
    "# Add base configuration\n",
    "config.update({\n",
    "    'data_folder': 'processed_data',\n",
    "    'age_csv_path': 'user_ages.csv',\n",
    "    'train_ratio': 0.7,\n",
    "    'val_ratio': 0.15,\n",
    "    'test_ratio': 0.15,\n",
    "    'random_seed': 42,\n",
    "    'min_points_per_subject': 100,\n",
    "    'stage1_physics_weight': 0.01,  # Low physics weight for speed\n",
    "    'stage2_reg_weight': 0.1,\n",
    "    'stage1_patience': 15,\n",
    "    'stage2_patience': 10,\n",
    "    'param_bounds': {\n",
    "        'K': (500.0, 3000.0),\n",
    "        'B': (20.0, 150.0),\n",
    "        'tau': (0.05, 0.4)\n",
    "    }\n",
    "})\n",
    "\n",
    "print(f\"\\nFinal config:\")\n",
    "print(f\"  Batch size: {config['batch_size']:,}\")\n",
    "print(f\"  Mixed precision: {config.get('mixed_precision', False)}\")\n",
    "print(f\"  Stage 1 epochs: {config['stage1_epochs']}\")\n",
    "print(f\"  Stage 2 epochs: {config['stage2_epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports and logging\n",
    "import logging\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import our modules\n",
    "from improved_models import SubjectPINN, AgeParameterModel\n",
    "from enhanced_datasets import SubjectAwareDataset, create_subject_splits, create_filtered_dataset\n",
    "from training_utils import SimplePhysicsLoss, ParameterRegularizationLoss, EarlyStopping\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✅ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimized datasets\n",
    "print(\"=== DATASET SETUP ===\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = SubjectAwareDataset(\n",
    "    processed_data_folder=config['data_folder'],\n",
    "    age_csv_path=config['age_csv_path'],\n",
    "    min_points_per_subject=config['min_points_per_subject']\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded: {len(dataset)} total points\")\n",
    "print(f\"Valid subjects: {len(dataset.valid_subjects)}\")\n",
    "\n",
    "# Create subject splits\n",
    "subject_splits = create_subject_splits(\n",
    "    dataset,\n",
    "    train_ratio=config['train_ratio'],\n",
    "    val_ratio=config['val_ratio'],\n",
    "    test_ratio=config['test_ratio'],\n",
    "    random_seed=config['random_seed']\n",
    ")\n",
    "\n",
    "# Create filtered datasets\n",
    "train_indices = create_filtered_dataset(dataset, subject_splits['train'])\n",
    "val_indices = create_filtered_dataset(dataset, subject_splits['val'])\n",
    "test_indices = create_filtered_dataset(dataset, subject_splits['test'])\n",
    "\n",
    "print(f\"Data splits:\")\n",
    "print(f\"  Train: {len(subject_splits['train'])} subjects, {len(train_indices):,} points\")\n",
    "print(f\"  Val:   {len(subject_splits['val'])} subjects, {len(val_indices):,} points\")\n",
    "print(f\"  Test:  {len(subject_splits['test'])} subjects, {len(test_indices):,} points\")\n",
    "\n",
    "# Create optimized data loaders\n",
    "train_loader = DataLoader(\n",
    "    Subset(dataset, train_indices),\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config.get('num_workers', 4),\n",
    "    pin_memory=config.get('pin_memory', True),\n",
    "    prefetch_factor=config.get('prefetch_factor', 2),\n",
    "    persistent_workers=config.get('persistent_workers', False),\n",
    "    drop_last=True  # Consistent batch sizes\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    Subset(dataset, val_indices),\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config.get('num_workers', 4),\n",
    "    pin_memory=config.get('pin_memory', True)\n",
    ")\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Batch size: {config['batch_size']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 1: Subject Parameter Learning\n",
    "print(\"=\" * 60)\n",
    "print(\"STAGE 1: TRAINING SUBJECT PINN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create Stage 1 model\n",
    "subject_pinn = SubjectPINN(\n",
    "    subject_ids=dataset.valid_subjects,\n",
    "    hidden_dims=[256, 256, 256, 256],\n",
    "    param_bounds=config['param_bounds']\n",
    ").to(device)\n",
    "\n",
    "# Model compilation for faster execution (PyTorch 2.0+)\n",
    "if config.get('compile_model', False) and hasattr(torch, 'compile'):\n",
    "    try:\n",
    "        subject_pinn = torch.compile(subject_pinn)\n",
    "        print(\"✅ Model compiled with torch.compile\")\n",
    "    except:\n",
    "        print(\"⚠️ Model compilation failed, using standard model\")\n",
    "\n",
    "# Optimized optimizer\n",
    "stage1_optimizer = torch.optim.AdamW(\n",
    "    subject_pinn.parameters(),\n",
    "    lr=config['stage1_lr'],\n",
    "    weight_decay=1e-5,\n",
    "    eps=1e-6,  # More stable for mixed precision\n",
    "    betas=(0.9, 0.95)  # Optimized for large batches\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "stage1_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    stage1_optimizer,\n",
    "    T_max=config['stage1_epochs'],\n",
    "    eta_min=config['stage1_lr'] * 0.01\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "stage1_loss_fn = SimplePhysicsLoss(weight=config['stage1_physics_weight']).to(device)\n",
    "stage1_early_stopping = EarlyStopping(patience=config['stage1_patience'])\n",
    "\n",
    "# Mixed precision setup\n",
    "scaler = GradScaler() if config.get('mixed_precision', False) else None\n",
    "use_amp = config.get('mixed_precision', False)\n",
    "physics_freq = config.get('physics_computation_frequency', 1)\n",
    "\n",
    "print(f\"Stage 1 model: {sum(p.numel() for p in subject_pinn.parameters()):,} parameters\")\n",
    "print(f\"Mixed precision: {use_amp}\")\n",
    "print(f\"Physics computation: every {physics_freq} batches\")\n",
    "print(f\"Expected time per epoch: 2-3 minutes (A100)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 Training Loop with GPU Performance Monitoring\n",
    "import time\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "stage1_metrics = []\n",
    "val_frequency = config.get('val_frequency', 5)\n",
    "\n",
    "# Performance monitoring\n",
    "batch_times = []\n",
    "epoch_start_time = time.time()\n",
    "\n",
    "for epoch in range(config['stage1_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training\n",
    "    subject_pinn.train()\n",
    "    train_losses = defaultdict(float)\n",
    "    train_samples = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Stage 1 Epoch {epoch+1}\")\n",
    "    for batch_idx, (t, age, xy_true, subject_idx) in enumerate(pbar):\n",
    "        batch_start = time.time()\n",
    "        \n",
    "        # Move to GPU with non_blocking for faster transfer\n",
    "        t = t.to(device, non_blocking=True).requires_grad_(True)\n",
    "        age = age.to(device, non_blocking=True)\n",
    "        xy_true = xy_true.to(device, non_blocking=True)\n",
    "        subject_idx = subject_idx.to(device, non_blocking=True)\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        with autocast(enabled=use_amp):\n",
    "            xy_pred, params = subject_pinn(t, subject_idx)\n",
    "            \n",
    "            # Data loss\n",
    "            data_loss = nn.functional.mse_loss(xy_pred, xy_true)\n",
    "            \n",
    "            # Physics loss (computed less frequently)\n",
    "            if batch_idx % physics_freq == 0:\n",
    "                physics_loss = stage1_loss_fn(t, xy_pred, params)\n",
    "            else:\n",
    "                physics_loss = torch.tensor(0.0, device=device)\n",
    "            \n",
    "            total_loss = data_loss + physics_loss\n",
    "        \n",
    "        # Backward pass with mixed precision\n",
    "        if use_amp:\n",
    "            scaler.scale(total_loss).backward()\n",
    "            scaler.unscale_(stage1_optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(subject_pinn.parameters(), max_norm=1.0)\n",
    "            scaler.step(stage1_optimizer)\n",
    "            scaler.update()\n",
    "            stage1_optimizer.zero_grad()\n",
    "        else:\n",
    "            stage1_optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(subject_pinn.parameters(), max_norm=1.0)\n",
    "            stage1_optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        batch_size = t.shape[0]\n",
    "        train_losses['data'] += data_loss.item() * batch_size\n",
    "        train_losses['physics'] += physics_loss.item() * batch_size\n",
    "        train_losses['total'] += (data_loss + physics_loss).item() * batch_size\n",
    "        train_samples += batch_size\n",
    "        \n",
    "        # Performance monitoring\n",
    "        batch_time = time.time() - batch_start\n",
    "        batch_times.append(batch_time)\n",
    "        samples_per_sec = batch_size / batch_time\n",
    "        \n",
    "        # Update progress\n",
    "        pbar.set_postfix({\n",
    "            'Data': f\"{data_loss.item():.1f}\",\n",
    "            'Physics': f\"{physics_loss.item():.4f}\",\n",
    "            'Speed': f\"{samples_per_sec:.0f} smp/s\"\n",
    "        })\n",
    "        \n",
    "        # Memory management\n",
    "        if batch_idx % config.get('empty_cache_frequency', 50) == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Epoch timing\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    avg_batch_time = np.mean(batch_times[-len(train_loader):])\n",
    "    avg_samples_per_sec = config['batch_size'] / avg_batch_time\n",
    "    \n",
    "    # Learning rate step\n",
    "    stage1_scheduler.step()\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_train_losses = {k: v / train_samples for k, v in train_losses.items()}\n",
    "    \n",
    "    # Validation (less frequent for speed)\n",
    "    if epoch % val_frequency == 0 or epoch == config['stage1_epochs'] - 1:\n",
    "        # Validation pass\n",
    "        subject_pinn.eval()\n",
    "        val_losses = defaultdict(float)\n",
    "        val_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for t, age, xy_true, subject_idx in val_loader:\n",
    "                t = t.to(device, non_blocking=True).requires_grad_(True)\n",
    "                xy_true = xy_true.to(device, non_blocking=True)\n",
    "                subject_idx = subject_idx.to(device, non_blocking=True)\n",
    "                \n",
    "                with autocast(enabled=use_amp):\n",
    "                    xy_pred, params = subject_pinn(t, subject_idx)\n",
    "                    data_loss = nn.functional.mse_loss(xy_pred, xy_true)\n",
    "                    physics_loss = stage1_loss_fn(t, xy_pred, params)\n",
    "                    total_loss = data_loss + physics_loss\n",
    "                \n",
    "                batch_size = t.shape[0]\n",
    "                val_losses['data'] += data_loss.item() * batch_size\n",
    "                val_losses['physics'] += physics_loss.item() * batch_size\n",
    "                val_losses['total'] += total_loss.item() * batch_size\n",
    "                val_samples += batch_size\n",
    "        \n",
    "        avg_val_losses = {k: v / val_samples for k, v in val_losses.items()}\n",
    "        val_loss = avg_val_losses['total']\n",
    "        \n",
    "        # GPU memory status\n",
    "        if torch.cuda.is_available():\n",
    "            memory_used = torch.cuda.memory_allocated() / 1024**3\n",
    "            memory_cached = torch.cuda.memory_reserved() / 1024**3\n",
    "            gpu_util_info = f\"GPU: {memory_used:.1f}GB used, {memory_cached:.1f}GB cached\"\n",
    "        else:\n",
    "            gpu_util_info = \"CPU mode\"\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{config['stage1_epochs']} - {epoch_time:.1f}s\")\n",
    "        print(f\"  Train: Data={avg_train_losses['data']:.1f}, Physics={avg_train_losses['physics']:.6f}\")\n",
    "        print(f\"  Val:   Data={avg_val_losses['data']:.1f}, Physics={avg_val_losses['physics']:.6f}\")\n",
    "        print(f\"  Speed: {avg_samples_per_sec:.0f} samples/sec\")\n",
    "        print(f\"  {gpu_util_info}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'model_state_dict': subject_pinn.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_loss': val_loss,\n",
    "                'config': config\n",
    "            }, 'best_stage1_model.pth')\n",
    "            print(f\"  ✅ Best model saved (val_loss={val_loss:.6f})\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if stage1_early_stopping(val_loss, subject_pinn):\n",
    "            print(f\"  🛑 Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Epoch {epoch+1}/{config['stage1_epochs']} - {epoch_time:.1f}s - Train Loss: {avg_train_losses['total']:.1f}\")\n",
    "\n",
    "print(f\"\\n✅ STAGE 1 COMPLETED!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.6f}\")\n",
    "print(f\"Total Stage 1 time: {(time.time() - epoch_start_time)/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Subject Parameters from Stage 1\n",
    "print(\"=== EXTRACTING SUBJECT PARAMETERS ===\")\n",
    "\n",
    "subject_pinn.eval()\n",
    "subject_parameters = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, subject_id in enumerate(dataset.valid_subjects):\n",
    "        subject_idx = torch.tensor([[i]], dtype=torch.long).to(device)\n",
    "        K, B, tau = subject_pinn.get_parameters(subject_idx.squeeze())\n",
    "        \n",
    "        subject_info = dataset.get_subject_info(subject_id)\n",
    "        age = subject_info.get('age', 0)\n",
    "        \n",
    "        subject_parameters[subject_id] = {\n",
    "            'age': age,\n",
    "            'K': K.item(),\n",
    "            'B': B.item(),\n",
    "            'tau': tau.item(),\n",
    "            'n_points': subject_info.get('n_points', 0)\n",
    "        }\n",
    "\n",
    "# Save parameters\n",
    "with open('subject_parameters.json', 'w') as f:\n",
    "    json.dump(subject_parameters, f, indent=2)\n",
    "\n",
    "# Parameter statistics\n",
    "ages = [p['age'] for p in subject_parameters.values()]\n",
    "Ks = [p['K'] for p in subject_parameters.values()]\n",
    "Bs = [p['B'] for p in subject_parameters.values()]\n",
    "taus = [p['tau'] for p in subject_parameters.values()]\n",
    "\n",
    "print(f\"Extracted parameters for {len(subject_parameters)} subjects:\")\n",
    "print(f\"  Age range: {min(ages):.1f} - {max(ages):.1f}\")\n",
    "print(f\"  K range: {min(Ks):.1f} - {max(Ks):.1f}\")\n",
    "print(f\"  B range: {min(Bs):.1f} - {max(Bs):.1f}\")\n",
    "print(f\"  τ range: {min(taus):.3f} - {max(taus):.3f}\")\n",
    "\n",
    "# Check parameter variation (should be >0.1 for good learning)\n",
    "K_cv = np.std(Ks) / np.mean(Ks)\n",
    "B_cv = np.std(Bs) / np.mean(Bs)\n",
    "tau_cv = np.std(taus) / np.mean(taus)\n",
    "\n",
    "print(f\"\\nParameter variation (coefficient of variation):\")\n",
    "print(f\"  K: {K_cv:.3f} {'✅' if K_cv > 0.1 else '❌'} (need >0.1)\")\n",
    "print(f\"  B: {B_cv:.3f} {'✅' if B_cv > 0.1 else '❌'} (need >0.1)\")\n",
    "print(f\"  τ: {tau_cv:.3f} {'✅' if tau_cv > 0.1 else '❌'} (need >0.1)\")\n",
    "\n",
    "if all(cv > 0.1 for cv in [K_cv, B_cv, tau_cv]):\n",
    "    print(\"\\n✅ Good parameter variation - Stage 1 learned meaningful differences!\")\nelse:\n",
    "    print(\"\\n⚠️ Low parameter variation - may need more training or different loss weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 2: Age Parameter Learning\n",
    "print(\"=\" * 60)\n",
    "print(\"STAGE 2: TRAINING AGE PARAMETER MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create Stage 2 model\n",
    "age_model = AgeParameterModel(\n",
    "    param_bounds=config['param_bounds'],\n",
    "    use_probabilistic=True\n",
    ").to(device)\n",
    "\n",
    "# Stage 2 optimizer\n",
    "stage2_optimizer = torch.optim.AdamW(\n",
    "    age_model.parameters(),\n",
    "    lr=config['stage2_lr'],\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "\n",
    "stage2_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    stage2_optimizer,\n",
    "    T_max=config['stage2_epochs']\n",
    ")\n",
    "\n",
    "# Loss functions\n",
    "stage2_reg_loss = ParameterRegularizationLoss(\n",
    "    smoothness_weight=0.1,\n",
    "    variation_weight=0.1, \n",
    "    param_bounds=config['param_bounds']\n",
    ").to(device)\n",
    "\n",
    "stage2_early_stopping = EarlyStopping(patience=config['stage2_patience'])\n",
    "\n",
    "print(f\"Stage 2 model: {sum(p.numel() for p in age_model.parameters()):,} parameters\")\n",
    "\n",
    "# Prepare Stage 2 data (age -> parameters)\n",
    "train_ages = []\n",
    "train_params = []\n",
    "val_ages = []\n",
    "val_params = []\n",
    "\n",
    "for subject_id in subject_splits['train']:\n",
    "    if subject_id in subject_parameters:\n",
    "        param_data = subject_parameters[subject_id]\n",
    "        train_ages.append(param_data['age'])\n",
    "        train_params.append([param_data['K'], param_data['B'], param_data['tau']])\n",
    "\n",
    "for subject_id in subject_splits['val']:\n",
    "    if subject_id in subject_parameters:\n",
    "        param_data = subject_parameters[subject_id]\n",
    "        val_ages.append(param_data['age'])\n",
    "        val_params.append([param_data['K'], param_data['B'], param_data['tau']])\n",
    "\n",
    "# Convert to tensors\n",
    "train_ages_tensor = torch.tensor(train_ages, dtype=torch.float32).unsqueeze(-1)\n",
    "train_params_tensor = torch.tensor(train_params, dtype=torch.float32)\n",
    "val_ages_tensor = torch.tensor(val_ages, dtype=torch.float32).unsqueeze(-1)\n",
    "val_params_tensor = torch.tensor(val_params, dtype=torch.float32)\n",
    "\n",
    "print(f\"Stage 2 data: {len(train_ages)} train, {len(val_ages)} val subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 Training Loop\n",
    "best_stage2_val_loss = float('inf')\n",
    "stage2_metrics = []\n",
    "\n",
    "stage2_start_time = time.time()\n",
    "\n",
    "for epoch in range(config['stage2_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training\n",
    "    age_model.train()\n",
    "    \n",
    "    # Shuffle training data\n",
    "    indices = torch.randperm(len(train_ages))\n",
    "    train_ages_shuffled = train_ages_tensor[indices].to(device)\n",
    "    train_params_shuffled = train_params_tensor[indices].to(device)\n",
    "    \n",
    "    train_losses = defaultdict(float)\n",
    "    n_batches = 0\n",
    "    \n",
    "    # Mini-batch training for Stage 2\n",
    "    batch_size = min(32, len(train_ages))  # Smaller batches for Stage 2\n",
    "    \n",
    "    for i in range(0, len(train_ages), batch_size):\n",
    "        batch_ages = train_ages_shuffled[i:i+batch_size]\n",
    "        batch_params = train_params_shuffled[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        with autocast(enabled=use_amp):\n",
    "            pred_means, pred_stds = age_model.predict_parameters(batch_ages)\n",
    "            \n",
    "            # Negative log-likelihood loss\n",
    "            param_loss = 0.5 * torch.mean(\n",
    "                ((batch_params - pred_means) / (pred_stds + 1e-6))**2 + \n",
    "                torch.log(pred_stds + 1e-6)\n",
    "            )\n",
    "            \n",
    "            # Regularization\n",
    "            reg_losses = stage2_reg_loss(batch_ages, batch_params)\n",
    "            total_reg_loss = sum(reg_losses.values())\n",
    "            \n",
    "            total_loss = param_loss + config['stage2_reg_weight'] * total_reg_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        if use_amp:\n",
    "            scaler.scale(total_loss).backward()\n",
    "            scaler.step(stage2_optimizer)\n",
    "            scaler.update()\n",
    "            stage2_optimizer.zero_grad()\n",
    "        else:\n",
    "            stage2_optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            stage2_optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        train_losses['param'] += param_loss.item()\n",
    "        train_losses['reg'] += total_reg_loss.item()\n",
    "        train_losses['total'] += total_loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    # Learning rate step\n",
    "    stage2_scheduler.step()\n",
    "    \n",
    "    # Average losses\n",
    "    avg_train_losses = {k: v / n_batches for k, v in train_losses.items()}\n",
    "    \n",
    "    # Validation\n",
    "    age_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_ages_gpu = val_ages_tensor.to(device)\n",
    "        val_params_gpu = val_params_tensor.to(device)\n",
    "        \n",
    "        with autocast(enabled=use_amp):\n",
    "            pred_means, pred_stds = age_model.predict_parameters(val_ages_gpu)\n",
    "            val_param_loss = 0.5 * torch.mean(\n",
    "                ((val_params_gpu - pred_means) / (pred_stds + 1e-6))**2 + \n",
    "                torch.log(pred_stds + 1e-6)\n",
    "            )\n",
    "            val_reg_losses = stage2_reg_loss(val_ages_gpu, val_params_gpu)\n",
    "            val_total_reg = sum(val_reg_losses.values())\n",
    "            val_total_loss = val_param_loss + config['stage2_reg_weight'] * val_total_reg\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Stage 2 Epoch {epoch+1}/{config['stage2_epochs']} - {epoch_time:.1f}s\")\n",
    "    print(f\"  Train: Param={avg_train_losses['param']:.6f}, Reg={avg_train_losses['reg']:.6f}\")\n",
    "    print(f\"  Val:   Param={val_param_loss.item():.6f}, Reg={val_total_reg.item():.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_total_loss.item() < best_stage2_val_loss:\n",
    "        best_stage2_val_loss = val_total_loss.item()\n",
    "        torch.save({\n",
    "            'subject_pinn_state_dict': subject_pinn.state_dict(),\n",
    "            'age_model_state_dict': age_model.state_dict(),\n",
    "            'subject_parameters': subject_parameters,\n",
    "            'config': config\n",
    "        }, 'best_two_stage_model.pth')\n",
    "        print(f\"  ✅ Best two-stage model saved\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if stage2_early_stopping(val_total_loss.item(), age_model):\n",
    "        print(f\"  🛑 Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n✅ STAGE 2 COMPLETED!\")\n",
    "print(f\"Best Stage 2 validation loss: {best_stage2_val_loss:.6f}\")\n",
    "print(f\"Total Stage 2 time: {(time.time() - stage2_start_time)/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Relationship Analysis and Visualization\n",
    "print(\"=== AGE RELATIONSHIP ANALYSIS ===\")\n",
    "\n",
    "age_model.eval()\n",
    "\n",
    "# Generate predictions across age range\n",
    "ages_test = np.linspace(20, 90, 100)\n",
    "age_tensor = torch.tensor(ages_test, dtype=torch.float32).unsqueeze(-1).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_means, pred_stds = age_model.predict_parameters(age_tensor)\n",
    "    pred_means = pred_means.cpu().numpy()\n",
    "    pred_stds = pred_stds.cpu().numpy()\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "param_names = ['Stiffness (K)', 'Damping (B)', 'Neural Delay (τ)']\n",
    "subject_params = [[p['K'] for p in subject_parameters.values()],\n",
    "                  [p['B'] for p in subject_parameters.values()],\n",
    "                  [p['tau'] for p in subject_parameters.values()]]\n",
    "subject_ages = [p['age'] for p in subject_parameters.values()]\n",
    "\n",
    "for i, (name, subject_param) in enumerate(zip(param_names, subject_params)):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot subject data\n",
    "    ax.scatter(subject_ages, subject_param, alpha=0.6, s=20, color='blue', label='Subjects')\n",
    "    \n",
    "    # Plot learned curve\n",
    "    ax.plot(ages_test, pred_means[:, i], 'red', linewidth=2, label='Learned Trend')\n",
    "    \n",
    "    # Plot uncertainty\n",
    "    ax.fill_between(ages_test, \n",
    "                   pred_means[:, i] - pred_stds[:, i],\n",
    "                   pred_means[:, i] + pred_stds[:, i],\n",
    "                   alpha=0.2, color='red', label='Uncertainty')\n",
    "    \n",
    "    ax.set_xlabel('Age (years)')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_title(f'{name} vs Age')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('parameter_age_relationships.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate age correlations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "correlations = {}\n",
    "for i, param_name in enumerate(['K', 'B', 'tau']):\n",
    "    param_values = [subject_parameters[sid][param_name] for sid in subject_splits['train'] if sid in subject_parameters]\n",
    "    param_ages = [subject_parameters[sid]['age'] for sid in subject_splits['train'] if sid in subject_parameters]\n",
    "    \n",
    "    if len(param_values) > 3:\n",
    "        corr, p_value = pearsonr(param_ages, param_values)\n",
    "        correlations[param_name] = {'correlation': corr, 'p_value': p_value}\n",
    "        print(f\"{param_name}-age correlation: {corr:.3f} (p={p_value:.3f})\")\n",
    "\n",
    "print(\"\\n✅ Age relationship analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Testing and Performance Summary\n",
    "print(\"=== FINAL MODEL TESTING ===\")\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('best_two_stage_model.pth')\n",
    "subject_pinn.load_state_dict(checkpoint['subject_pinn_state_dict'])\n",
    "age_model.load_state_dict(checkpoint['age_model_state_dict'])\n",
    "\n",
    "print(\"✅ Best models loaded\")\n",
    "\n",
    "# Test age comparison functionality\n",
    "def compare_ages(age1: float, age2: float):\n",
    "    \"\"\"Compare balance parameters between two ages.\"\"\"\n",
    "    age1_tensor = torch.tensor([[age1]], device=device)\n",
    "    age2_tensor = torch.tensor([[age2]], device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        params1_mean, _ = age_model.predict_parameters(age1_tensor)\n",
    "        params2_mean, _ = age_model.predict_parameters(age2_tensor)\n",
    "        \n",
    "        # Calculate parameter differences\n",
    "        param_diff = (params2_mean - params1_mean).cpu().numpy().squeeze()\n",
    "        \n",
    "        return {\n",
    "            'age1_params': params1_mean.cpu().numpy().squeeze(),\n",
    "            'age2_params': params2_mean.cpu().numpy().squeeze(),\n",
    "            'differences': param_diff\n",
    "        }\n",
    "\n",
    "# Test age comparisons\n",
    "print(\"\\n=== AGE COMPARISON TEST ===\")\n",
    "test_comparisons = [\n",
    "    (30, 60),  # Young vs middle-aged\n",
    "    (40, 70),  # Middle-aged vs older\n",
    "    (60, 80),  # Older vs elderly\n",
    "]\n",
    "\n",
    "for age1, age2 in test_comparisons:\n",
    "    comparison = compare_ages(age1, age2)\n",
    "    print(f\"\\nAge {age1} vs {age2}:\")\n",
    "    print(f\"  K: {comparison['age1_params'][0]:.1f} → {comparison['age2_params'][0]:.1f} (Δ={comparison['differences'][0]:+.1f})\")\n",
    "    print(f\"  B: {comparison['age1_params'][1]:.1f} → {comparison['age2_params'][1]:.1f} (Δ={comparison['differences'][1]:+.1f})\")\n",
    "    print(f\"  τ: {comparison['age1_params'][2]:.3f} → {comparison['age2_params'][2]:.3f} (Δ={comparison['differences'][2]:+.3f})\")\n",
    "\n",
    "print(\"\\n✅ Age comparison functionality working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Summary and Model Download\n",
    "total_training_time = time.time() - epoch_start_time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n📊 PERFORMANCE SUMMARY:\")\n",
    "if torch.cuda.is_available():\n",
    "    final_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "    max_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
    "    print(f\"  GPU Memory: {final_memory:.1f}GB current, {max_memory:.1f}GB peak\")\n",
    "\n",
    "print(f\"  Total training time: {total_training_time/60:.1f} minutes\")\n",
    "print(f\"  Stage 1 epochs: {config['stage1_epochs']}\")\n",
    "print(f\"  Stage 2 epochs: {config['stage2_epochs']}\")\n",
    "print(f\"  Final batch size: {config['batch_size']:,}\")\n",
    "\n",
    "print(f\"\\n🎯 MODEL RESULTS:\")\n",
    "print(f\"  Subjects processed: {len(subject_parameters)}\")\n",
    "print(f\"  Parameter variation: K={K_cv:.3f}, B={B_cv:.3f}, τ={tau_cv:.3f}\")\n",
    "print(f\"  Age relationships learned: {'✅' if all(abs(corr['correlation']) > 0.1 for corr in correlations.values()) else '⚠️'}\")\n",
    "\n",
    "print(f\"\\n📁 SAVED FILES:\")\n",
    "print(f\"  best_two_stage_model.pth - Complete trained model\")\n",
    "print(f\"  subject_parameters.json - Individual subject parameters\")\n",
    "print(f\"  parameter_age_relationships.png - Visualization\")\n",
    "\n",
    "print(f\"\\n🚀 Ready for cross-age balance comparison!\")\n",
    "\n",
    "# Download instructions\n",
    "from google.colab import files\n",
    "print(f\"\\n📥 DOWNLOAD TRAINED MODELS:\")\n",
    "print(f\"Run these commands to download your trained models:\")\n",
    "print(f\"files.download('best_two_stage_model.pth')\")\n",
    "print(f\"files.download('subject_parameters.json')\")\n",
    "print(f\"files.download('parameter_age_relationships.png')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}